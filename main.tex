\RequirePackage{plautopatch}
\documentclass[uplatex,dvipdfmx]{jlreq}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}

\newcommand\term[1]{\textsf{#1}}
\newtheorem{example}{例}
\newtheorem{note}{注}
\newtheorem{theorem}{定理}

\begin{document}

\title{確率と統計的推定の基本}
\maketitle

\section{確率の基本}

\subsection{確率空間}

起こりうる試行結果全体の集合を\term{標本空間 (sample space)}という。標本空間の部分集合を\term{事象 (event)}といい、標本空間の1つの要素からなる事象を\term{根元事象 (elementary event)}という。

この文書では標本空間の要素が有限個の場合のみ扱う。登場する和も全て有限和。

標本空間$\Omega$上の実数値関数で以下を満たす$P$を\term{確率 (probability)}とする。

\begin{equation}
    0 \leq P(\omega) \leq 1,
    \quad \sum_{\omega\in\Omega} P(\omega) = 1
\end{equation}

（本来は$P(\{\omega\})$と書くべき）

$\Omega$の部分集合$A$の確率も以下のように定義できる。

\begin{equation}
    P(A) := \sum_{\omega\in A}P(\omega)
\end{equation}

$A$の要素が満たす条件を使って、以下のように書くこともある。

\begin{equation}
    P(A) = P(\{\omega|\omega\in A\}) = P\{\omega\in A\}
\end{equation}

確率が与えられた標本空間を\term{確率空間 (probability space)}と呼ぶ。

\begin{note}
    標本空間がより一般の場合（特に連続濃度を持つ場合など）、数学的には測度論の言葉を使って定義される。その場合、標本空間は可測空間、事象は可測集合、確率は確率測度に対応する。
\end{note}

\subsection{確率変数}

確率空間$\Omega$上の関数、すなわち各根元事象$\omega$に対して数（やベクトル）を対応させるものを\term{確率変数 (probabilistic variable)}と呼ぶ。確率変数であることを強調するために、$X, Y$といった大文字の変数名にすることもある。

実際に出てくる例では、確率空間$\Omega$自体が数やベクトル空間になっていることも多く、この場合は根元事象$\omega$自体を確率変数と捉えてよい。

\begin{example}
    コイン投げを2回行った時の表裏の出方を考える。表を$H$, 裏を$T$と書くと、標本空間は$\Omega=\{(H, H), (H, T), (T, H), (T, T)\}$. 表が出た回数を考えるとこれは関数$f\colon \Omega \to \{0, 1, 2\}$であり、確率変数。
\end{example}

\begin{example}
    サイコロを1回投げて出た目の事象を考えると、$\Omega=\{1, 2, 3, 4, 5, 6\}$としてよく、根元事象自体を確率変数$X$と思うことができる。$X$の関数も確率変数（$X^2$, $e^X$, $(X, X^2, X^3)$など）。
\end{example}

\subsection{確率分布}

確率空間$\Omega$上の確率変数$X\colon \Omega \to E$に対して、その\term{確率分布 (probability distribution)}（単に分布と呼ぶこともある）を考えることができる。

\begin{equation}
    p_X(x) := P(\{\omega | X(\omega) = x\})
    = P\{X(\omega) = x\}
    = \sum_{\omega \in \Omega, X(\omega) = x} P(\omega)
\end{equation}

文脈上明らかな時は$p_X(x)$のことを単に$p(x)$と書くことも多い。明らかに以下の性質が成り立つ。

\begin{equation}
    0 \leq p_X(x) \leq 1, \quad \sum_x p_X(x) = 1
\end{equation}

\begin{note}
    より正確には、確率分布とは$X$が部分集合$A$ ($\subset E$) 内に値を取る確率（測度）のことを言う。$X$の取りうる値が離散的な場合、1点$x$を取る確率 $p_X(x)$ を\term{確率質量関数 (probability mass function)}と呼ぶ。$X$が連続的な値を取りうる場合、\term{累積分布関数 (cumulative distribution function)}や\term{確率密度関数 (probability density function)}を考える必要がある。
\end{note}

共通の確率空間$\Omega$上の2つの確率変数$X$, $Y$に対して、$(X, Y)$も確率変数である。$(X, Y)$の確率分布$p_{(X, Y)}(x, y)$を\term{同時確率分布 (joint probability distribution)}という。逆に、同時分布から導いた$X$, $Y$単独の分布を\term{周辺確率分布 (marginal probability distribution)}という。周辺分布は、同時分布から以下のように計算できる。

\begin{equation}
    p_X(x) = \sum_y p_{(X, Y)}(x, y),\quad
    p_Y(y) = \sum_x p_{(X, Y)}(x, y)
\end{equation}

\subsection{確率変数の期待値・分散}

確率変数$X(\omega)$とその分布$p_X(x)$が与えられた時、$X$の\term{期待値 (expectation value)}は以下で定義される数である。

\begin{equation}
    E[X] := \sum_x x \cdot p_X(x)
\end{equation}

確率変数$X$は確率的に値$x$を取るものであるのに対して、期待値$E[X]$は確定した値であることに注意。

\begin{note}
    期待値のことを平均ということもあるが、個人的には後述の標本平均と紛らわしいと思うので、この文書では常に期待値と呼ぶ。
\end{note}

$X$の関数$Y=f(X)$もまた確率変数であり、$Y$の期待値を考えることができる。

\begin{equation}
    E[Y] := \sum_y y \cdot p_Y(y) = \sum_x f(x)p_X(x)
\end{equation}

\begin{note}
    $X$が連続的な値を取る場合、期待値は積分で定義される。その場合、$Y$の期待値計算は積分の変数変換となり、$f'(x)$をかける必要があることに注意。
\end{note}

確率変数の線型結合に関して、期待値は線形であることが定義から分かる。

\begin{equation}
    E[aX + bY] = aE[X] + bE[Y]
\end{equation}

確率変数$X$に対して、その期待値からのずれの2乗$(X-E[X])^2$も確率変数である。これの期待値を$X$の\term{分散 (variance)}と呼ぶ。

\begin{equation}
    V[X] := E[(X-E[X])^2] = \sum_x (x-E[X])^2 p_X(x)
\end{equation}

分散の2乗根$\sqrt{V[X]}$を\term{標準偏差 (standard deviation)}と呼び、$\sigma$で書くことが多い。これを使って分散を$\sigma^2$と書くこともある。（なぜか$\sigma[X]$という表記はあまり見ない気がする）

分散の定義から以下が導ける。

\begin{equation}
    V[X] := E[(X-E[X])^2] = E[X^2] - E[X]^2
\end{equation}

2つの確率変数$X, Y$について、それぞれの期待値からのずれの積の期待値を$X$, $Y$の\term{共分散 (covariance)}と呼ぶ。

\begin{equation}
    \operatorname{Cov}[X, Y] :=
    E[(X-E[X])(Y-E[Y])]
\end{equation}

定義から以下の関係が成り立つ。

\begin{equation}
    V[X + Y] = V[X] + V[Y] + 2\operatorname{Cov}[X, Y]
\end{equation}

分散が満たす重要な性質として、\term{チェビシェフの不等式 (Chebyshev's inequality)}がある。

\begin{theorem}[チェビシェフの不等式]
    確率変数$X$の期待値$\mu:=E[X]$, 分散$\sigma^2:=V[X] (>0)$に対して、任意の正数$a$について以下が成り立つ。
    \begin{equation}
        P\{|X - \mu| \geq a\sigma\} \leq \frac{1}{a^2}
    \end{equation}
\end{theorem}

例えば$a=2$とすると、$X$が期待値$\mu$から$2\sigma$以上離れた値を取る確率が$1/4$以下になる。期待値から離れるほど、その確率が小さくなっていくことが分かる。一方、$a=1$とすると確率が1以下という自明な関係になり、実質的に制約にならないことに注意。たとえば正規分布を考えると、$|X-\mu|\geq\sigma$となる確率は約32\%であり、チェビシェフの不等式より強い制約がかかっていることが分かる。

\subsection{独立性}

2つの事象間、2つの確率変数間の独立性が定義できる。

2つの事象$A, B$が\term{独立 (independent)}とは、$P(A \cap B) = P(A)P(B)$が成り立つことである。

共通の確率空間$\Omega$上の2つの確率変数$X$, $Y$が\term{独立 (independent)}とは、$X$, $Y$の取りうる値の任意の集合$A_X$, $B_Y$について、

\begin{equation}
    P(\{\omega|X(\omega)\in A_X, Y(\omega)\in B_Y\}) =
    P(\{\omega|X(\omega)\in A_X\})P(\{\omega|Y(\omega)\in B_Y\})
\end{equation}

が成り立つことであるが、これは任意の$x, y$に対して以下が成り立つことと同値である。

\begin{equation}
    p_{(X, Y)}(x, y) = p_X(x) p_Y(y)
\end{equation}

すなわち、同時確率分布が周辺確率分布の積になっているということ。

確率変数$X, Y$が独立なら、任意の関数$f$, $g$に対して$f(X)$, $g(Y)$も独立。

確率変数$X, Y$が独立なら、その積の期待値は、期待値の積と一致する（逆は成り立たないことに注意）。

\begin{equation}
    E[XY] = E[X]E[Y]
\end{equation}

これを使うとさらに、共分散が0であり、和の分散が分散の和に一致することも分かる。

\begin{equation}
    \operatorname{Cov}[X, Y] = 0,\quad V[X + Y] = V[X] + V[Y]
\end{equation}

\section{統計的推定の基本}

ここまでは、確率変数の分布が与えられ、その分布に関する値（期待値や分散など）を導入した。一方実用的には、これらの値が未知であり、確率変数の実現値（観測値）からこれらの値を推定することが重要である。

\subsection{統計的推定の問題設定}

確率分布が1つ与えられた時に、それに対して決まっている値のことを\term{母数}または\term{パラメーター (parameter)}と呼び、$\theta$で書くことが多い。$\theta$は実数でもよいしベクトルでもよい。

\begin{note}
    「母数」は日本語特有の用語であり、英語では``parameter''である。個人的には、母数という言葉は（有限な）統計的母集団の統計量（後述）というイメージが付随するように思うので、この文書では使わないことにして、常に「パラメーター」を使うことにする。また、母数という言葉を「母集団の大きさ」という意味で使う誤用も多い。
\end{note}

統計的推定問題では、未知のパラメーター$\theta$の推定を考える。これはすなわち、複数の確率分布からなる確率分布族$\mathcal{P}$を考えることになる。$\mathcal{P}$を\term{確率モデル (probabilistic model)}という。$\theta$を決めると$\mathcal{P}$内の分布が一意に決まる場合、すなわち$\mathcal{P} = \{ P_\theta | \theta \in \Theta \}$となる場合、$\mathcal{P}$を\term{パラメトリックモデル (parametric model)}と呼ぶ。反対に、$\mathcal{P}$がパラメーターで特徴づけられない場合\term{ノンパラメトリックモデル (non-parametric model)}と呼ぶ。

\begin{example}
    任意の$\mu\in\mathbb{R}$, $\sigma^2(>0)\in\mathbb{R}$に対して、正規分布$N(\mu, \sigma^2)$は1つ決まるので、これを集めた分布族は$(\mu, \sigma^2)$をパラメーターとするパラメトリックモデル。
\end{example}

\begin{example}
    確率分布$p_X(x)$の形が不明でも、その期待値$\mu$および分散$\sigma^2$は分布に対して決まるパラメーターなので、その推定問題を考えることができる。この場合はノンパラメトリックモデルと考えられる。
\end{example}

さて、未知の確率分布にしたがう確率変数$X$について、その分布のパラメーターを推定したいのであるが、$X$の実現値を1つ取っただけではよい推定ができない（推定の良さについては後述）。したがって、同じ確率分布$p(x)$にしたがう独立な$n$個の確率変数$\boldsymbol{X} := (X_1, \dotsc, X_n)$を使って推定を行うことが多い。同じ分布にしたがう独立な複数の確率変数を考えるとき、それらを\term{独立同分布 (independent and identically distributed, i.i.d.)}であるという。独立同分布の$n$個の確率変数の分布は以下のようになる。

\begin{equation}
    p_{\boldsymbol{X}}(x_1, \dotsc, x_n) = p(x_1) \dotsm p(x_n)
\end{equation}

このように得られた$X_1, \dotsc, X_n$を、\term{大きさ$n$の無作為標本 (random sample of size $n$)}という。

\begin{note}
    これを「$n$個のサンプル」というのは本来の意味では正しくないらしい。$n$は1つのサンプルの大きさであり、サンプルの「個数」はこの大きさ$n$のサンプルが何個あるかを指す、というのが正確な言葉の使い方とのこと。
\end{note}

以下では$\boldsymbol{X}=(X_1, \dotsc, X_n)$を使って、元の分布$p(x)$のパラメーターを推定することを考える。

\begin{note}
    実際の問題において、$n$個の確率変数が得られた際に、それらが独立同分布であるかを意識することは重要だと思う。$n$個の値が得られるがそれらが実は独立ではない（し同分布でもない）という場合、以下で示す性質は成り立たないかもしれない。逆に、以下で示す種々の性質の導出で、独立同分布性を使っているかを意識しておくとよいかもしれない。
\end{note}

\end{document}
