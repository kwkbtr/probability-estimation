\RequirePackage{plautopatch}
\documentclass[uplatex,dvipdfmx]{jlreq}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{thmtools}

\newcommand\term[1]{\textsf{#1}}
\declaretheorem[name=例,qed=\qedsymbol]{example}
\declaretheorem[name=注,qed=$\lhd$]{note}
\declaretheorem[name=定理,qed=\qedsymbol]{theorem}

\begin{document}

\title{確率と統計的推定の基本}
\maketitle

\section{確率の基本}

\subsection{確率空間}

起こりうる試行結果全体の集合を\term{標本空間 (sample space)}という。標本空間の部分集合を\term{事象 (event)}といい、標本空間の1つの要素からなる事象を\term{根元事象 (elementary event)}という。

この文書では標本空間の要素が有限個の場合のみ扱う。登場する和も全て有限和。

標本空間$\Omega$上の実数値関数で以下を満たす$P$を\term{確率 (probability)}とする。

\begin{equation}
    0 \leq P(\omega) \leq 1,
    \quad \sum_{\omega\in\Omega} P(\omega) = 1
\end{equation}

（本来は$P(\{\omega\})$と書くべき）

$\Omega$の部分集合$A$の確率も以下のように定義できる。

\begin{equation}
    P(A) := \sum_{\omega\in A}P(\omega)
\end{equation}

$A$の要素が満たす条件を使って、以下のように書くこともある。

\begin{equation}
    P(A) = P(\{\omega|\omega\in A\}) = P\{\omega\in A\}
\end{equation}

確率が与えられた標本空間を\term{確率空間 (probability space)}と呼ぶ。

\begin{note}
    標本空間がより一般の場合（特に連続濃度を持つ場合など）、数学的には測度論の言葉を使って定義される。その場合、標本空間は可測空間、事象は可測集合、確率は確率測度に対応する。
\end{note}

\subsection{確率変数}

確率空間$\Omega$上の関数、すなわち各根元事象$\omega$に対して数（やベクトル）を対応させるものを\term{確率変数 (probabilistic variable)}と呼ぶ。確率変数であることを強調するために、$X, Y$といった大文字の変数名にすることもある。

実際に出てくる例では、確率空間$\Omega$自体が数やベクトル空間になっていることも多く、この場合は根元事象$\omega$自体を確率変数と捉えてよい。

\begin{example}
    コイン投げを2回行った時の表裏の出方を考える。表を$H$, 裏を$T$と書くと、標本空間は$\Omega=\{(H, H), (H, T), (T, H), (T, T)\}$. 表が出た回数を考えるとこれは関数$f\colon \Omega \to \{0, 1, 2\}$であり、確率変数。
\end{example}

\begin{example}
    サイコロを1回投げて出た目の事象を考えると、$\Omega=\{1, 2, 3, 4, 5, 6\}$としてよく、根元事象自体を確率変数$X$と思うことができる。$X$の関数も確率変数（$X^2$, $e^X$, $(X, X^2, X^3)$など）。
\end{example}

\subsection{確率分布}

確率空間$\Omega$上の確率変数$X\colon \Omega \to E$に対して、その\term{確率分布 (probability distribution)}（単に分布と呼ぶこともある）を考えることができる。

\begin{equation}
    p_X(x) := P(\{\omega | X(\omega) = x\})
    = P\{X(\omega) = x\}
    = \sum_{\omega \in \Omega, X(\omega) = x} P(\omega)
\end{equation}

文脈上明らかな時は$p_X(x)$のことを単に$p(x)$と書くことも多い。明らかに以下の性質が成り立つ。

\begin{equation}
    0 \leq p_X(x) \leq 1, \quad \sum_x p_X(x) = 1
\end{equation}

\begin{note}
    より正確には、確率分布とは$X$が部分集合$A$ ($\subset E$) 内に値を取る確率（測度）のことを言う。$X$の取りうる値が離散的な場合、1点$x$を取る確率 $p_X(x)$ を\term{確率質量関数 (probability mass function)}と呼ぶ。$X$が連続的な値を取りうる場合、\term{累積分布関数 (cumulative distribution function)}や\term{確率密度関数 (probability density function)}を考える必要がある。
\end{note}

共通の確率空間$\Omega$上の2つの確率変数$X$, $Y$に対して、$(X, Y)$も確率変数である。$(X, Y)$の確率分布$p_{(X, Y)}(x, y)$を\term{同時確率分布 (joint probability distribution)}という。逆に、同時分布から導いた$X$, $Y$単独の分布を\term{周辺確率分布 (marginal probability distribution)}という。周辺分布は、同時分布から以下のように計算できる。

\begin{equation}
    p_X(x) = \sum_y p_{(X, Y)}(x, y),\quad
    p_Y(y) = \sum_x p_{(X, Y)}(x, y)
\end{equation}

\subsection{確率変数の期待値・分散}

確率変数$X(\omega)$とその分布$p_X(x)$が与えられた時、$X$の\term{期待値 (expectation value)}は以下で定義される数である。

\begin{equation}
    E[X] := \sum_x x \cdot p_X(x)
\end{equation}

確率変数$X$は確率的に値$x$を取るものであるのに対して、期待値$E[X]$は確定した値であることに注意。

\begin{note}
    期待値のことを平均ということもあるが、個人的には後述の標本平均と紛らわしいと思うので、この文書では常に期待値と呼ぶ。
\end{note}

$X$の関数$Y=f(X)$もまた確率変数であり、$Y$の期待値を考えることができる。

\begin{equation}
    E[Y] := \sum_y y \cdot p_Y(y) = \sum_x f(x)p_X(x)
\end{equation}

\begin{note}
    $X$が連続的な値を取る場合、期待値は積分で定義される。その場合、$Y$の期待値計算は積分の変数変換となり、$f'(x)$をかける必要があることに注意。
\end{note}

確率変数の線型結合に関して、期待値は線形であることが定義から分かる。

\begin{equation}
    E[aX + bY] = aE[X] + bE[Y]
\end{equation}

確率変数$X$に対して、その期待値からのずれの2乗$(X-E[X])^2$も確率変数である。これの期待値を$X$の\term{分散 (variance)}と呼ぶ。

\begin{equation}
    V[X] := E[(X-E[X])^2] = \sum_x (x-E[X])^2 p_X(x)
\end{equation}

分散の2乗根$\sqrt{V[X]}$を\term{標準偏差 (standard deviation)}と呼び、$\sigma$で書くことが多い。これを使って分散を$\sigma^2$と書くこともある。（なぜか$\sigma[X]$という表記はあまり見ない気がする）

分散の定義から以下が導ける。

\begin{equation}
    V[X] := E[(X-E[X])^2] = E[X^2] - E[X]^2
\end{equation}

2つの確率変数$X, Y$について、それぞれの期待値からのずれの積の期待値を$X$, $Y$の\term{共分散 (covariance)}と呼ぶ。

\begin{equation}
    \operatorname{Cov}[X, Y] :=
    E[(X-E[X])(Y-E[Y])]
\end{equation}

定義から以下の関係が成り立つ。

\begin{equation}
    V[X + Y] = V[X] + V[Y] + 2\operatorname{Cov}[X, Y]
\end{equation}

分散が満たす重要な性質として、\term{チェビシェフの不等式 (Chebyshev's inequality)}がある。

\begin{theorem}[チェビシェフの不等式]
    確率変数$X$の期待値$\mu:=E[X]$, 分散$\sigma^2:=V[X] (>0)$に対して、任意の正数$a$について以下が成り立つ。
    \begin{equation}
        P\{|X - \mu| \geq a\sigma\} \leq \frac{1}{a^2}
    \end{equation}
\end{theorem}

例えば$a=2$とすると、$X$が期待値$\mu$から$2\sigma$以上離れた値を取る確率が$1/4$以下になる。期待値から離れるほど、その確率が小さくなっていくことが分かる。一方、$a=1$とすると確率が1以下という自明な関係になり、実質的に制約にならないことに注意。たとえば正規分布を考えると、$|X-\mu|\geq\sigma$となる確率は約32\%であり、チェビシェフの不等式より強い制約がかかっていることが分かる。

\subsection{独立性}

2つの事象間、2つの確率変数間の独立性が定義できる。

2つの事象$A, B$が\term{独立 (independent)}とは、$P(A \cap B) = P(A)P(B)$が成り立つことである。

共通の確率空間$\Omega$上の2つの確率変数$X$, $Y$が\term{独立 (independent)}とは、$X$, $Y$の取りうる値の任意の集合$A_X$, $B_Y$について、

\begin{equation}
    P(\{\omega|X(\omega)\in A_X, Y(\omega)\in B_Y\}) =
    P(\{\omega|X(\omega)\in A_X\})P(\{\omega|Y(\omega)\in B_Y\})
\end{equation}

が成り立つことであるが、これは任意の$x, y$に対して以下が成り立つことと同値である。

\begin{equation}
    p_{(X, Y)}(x, y) = p_X(x) p_Y(y)
\end{equation}

すなわち、同時確率分布が周辺確率分布の積になっているということ。

確率変数$X, Y$が独立なら、任意の関数$f$, $g$に対して$f(X)$, $g(Y)$も独立。

確率変数$X, Y$が独立なら、その積の期待値は、期待値の積と一致する（逆は成り立たないことに注意）。

\begin{equation}
    E[XY] = E[X]E[Y]
\end{equation}

これを使うとさらに、共分散が0であり、和の分散が分散の和に一致することも分かる。

\begin{equation}
    \operatorname{Cov}[X, Y] = 0,\quad V[X + Y] = V[X] + V[Y]
\end{equation}

\section{統計的推定の基本}

ここまでは、確率変数の分布が与えられ、その分布に関する値（期待値や分散など）を導入した。一方実用的には、これらの値が未知であり、確率変数の実現値（観測値）からこれらの値を推定することが重要である。

\subsection{統計的推定の問題設定}

確率分布が1つ与えられた時に、それに対して決まっている値のことを\term{母数}または\term{パラメーター (parameter)}と呼び、$\theta$で書くことが多い。$\theta$は実数でもよいしベクトルでもよい。

\begin{note}
    「母数」は日本語特有の用語であり、英語では``parameter''である。個人的には、母数という言葉は（有限な）統計的母集団の統計量（後述）というイメージが付随するように思うので、この文書では使わないことにして、常に「パラメーター」を使うことにする。また、母数という言葉を「母集団の大きさ」という意味で使う誤用も多い。
\end{note}

統計的推定問題では、未知のパラメーター$\theta$の推定を考える。これはすなわち、複数の確率分布からなる確率分布族$\mathcal{P}$を考えることになる。$\mathcal{P}$を\term{確率モデル (probabilistic model)}という。$\theta$を決めると$\mathcal{P}$内の分布が一意に決まる場合、すなわち$\mathcal{P} = \{ P_\theta | \theta \in \Theta \}$となる場合、$\mathcal{P}$を\term{パラメトリックモデル (parametric model)}と呼ぶ。反対に、$\mathcal{P}$がパラメーターで特徴づけられない場合\term{ノンパラメトリックモデル (non-parametric model)}と呼ぶ。

\begin{example}
    任意の$\mu\in\mathbb{R}$, $\sigma^2(>0)\in\mathbb{R}$に対して、正規分布$N(\mu, \sigma^2)$は1つ決まるので、これを集めた分布族は$(\mu, \sigma^2)$をパラメーターとするパラメトリックモデル。
\end{example}

\begin{example}
    確率分布$p_X(x)$の形が不明でも、その期待値$\mu$および分散$\sigma^2$は分布に対して決まるパラメーターなので、その推定問題を考えることができる。この場合はノンパラメトリックモデルと考えられる。
\end{example}

さて、未知の確率分布にしたがう確率変数$X$について、その分布のパラメーターを推定したいのであるが、$X$の実現値を1つ取っただけではよい推定ができない（推定の良さについては後述）。したがって、同じ確率分布$p(x)$にしたがう独立な$n$個の確率変数$\boldsymbol{X} := (X_1, \dotsc, X_n)$を使って推定を行うことが多い。同じ分布にしたがう独立な複数の確率変数を考えるとき、それらを\term{独立同分布 (independent and identically distributed, i.i.d.)}であるという。独立同分布の$n$個の確率変数の分布は以下のようになる。

\begin{equation}
    p_{\boldsymbol{X}}(x_1, \dotsc, x_n) = p(x_1) \dotsm p(x_n)
\end{equation}

このように得られた$X_1, \dotsc, X_n$を、\term{大きさ$n$の無作為標本 (random sample of size $n$)}という。

\begin{note}
    これを「$n$個のサンプル」というのは本来の意味では正しくないらしい。$n$は1つのサンプルの大きさであり、サンプルの「個数」はこの大きさ$n$のサンプルが何個あるかを指す、というのが正確な言葉の使い方とのこと。
\end{note}

以下では$\boldsymbol{X}=(X_1, \dotsc, X_n)$を使って、元の分布$p(x)$のパラメーターを推定することを考える。

\begin{note}
    実際の問題において、$n$個の確率変数が得られた際に、それらが独立同分布であるかを意識することは重要だと思う。$n$個の値が得られるがそれらが実は独立ではない（し同分布でもない）という場合、以下で示す性質は成り立たないかもしれない。逆に、以下で示す種々の性質の導出で、独立同分布性を使っているかを意識しておくとよいかもしれない。
\end{note}

\subsection{推定量と不偏性}

無作為標本$X_1, \dotsc, X_n$の関数を\term{統計量 (statistic)}という。統計量は、未知の分布パラメーターを使わず、標本（の実現値）のみから計算できる量であり、「観測データから計算できる量」と言える。

\begin{example}[標本平均]
    以下で定義される$\bar{X}$は\term{標本平均 (sample mean)}と呼ばれる基本的な統計量である。
    \begin{equation}
        \bar{X} := \frac{1}{n} \sum_{i=1}^n X_i
    \end{equation}
\end{example}

未知の分布パラメーター$\theta$に対し、$\theta$の値を推定すると思われる統計量$\hat{\theta}(\boldsymbol{X})$のことを$\theta$の\term{推定量 (estimator)}と呼ぶ。また、$\theta$の関数$g(\theta)$の推定量$\hat{g}(\boldsymbol{X})$を考えることもある。この「定義」自体は、統計量であること以外に推定量の性質を制限していないことに注意。どんな関数でも（例えば定数関数$\hat{\theta}(\boldsymbol{X}):=1$でも）、「$\theta$の推定量」と呼ぶことはできる。したがって、考えている推定量が何らかの意味で「良い」推定量になっているかが重要である。

もっとも基本的な推定量の「良さ」の概念として\term{不偏性 (unbiasedness)}がある。$g(\theta)$の推定量$\hat{g}(\boldsymbol{X})$の期待値を
\begin{equation}
    E[\hat{g}(\boldsymbol{X})] = g(\theta) + b
\end{equation}
とするとき、真の値$g(\theta)$からのずれ$b := E[\hat{g}(\boldsymbol{X})] - g(\theta)$を\term{偏り (bias)}と呼ぶ。
（$\theta$に関するパラメトリックモデルを考えている場合は、$b$も$\theta$の関数となり、分布$P_\theta$による期待値を$E_\theta[\cdot]$と書くと
\begin{equation}
    E_\theta[\hat{g}(\boldsymbol{X})] = g(\theta) + b(\theta)
\end{equation}
となる。）今考えている全ての分布に関して常に$b=0$になる時、すなわち
\begin{equation}
    E[\hat{g}(\boldsymbol{X})] = g(\theta)
\end{equation}
が成り立つ時、$\hat{g}$を$g(\theta)$の\term{平均不偏推定量 (mean unbiased estimator)}あるいは単に\term{不偏推定量 (unbiased estimator)}という。これは、$\hat{g}(\boldsymbol{X})$の値は確率的に変動するが、平均的には$g(\theta)$に近いことを意味している。

\begin{example}[期待値の不偏推定量]\label{u_est_exp}
    標本$X_1, \dotsc, X_n$のそれぞれが、期待値$\mu$の分布にしたがうとする。この時、標本平均$\bar{X}$は期待値$\mu$の不偏推定量である。
    \begin{equation}
        E[\bar{X}] = E\left[\frac{1}{n}\sum_{i=1}^n X_i\right]
        = \frac{1}{n}\sum_{i=1}^n E[X_i] = \mu
    \end{equation}
    この導出で使用しているのは、各$X_i$の期待値が$\mu$であるという前提のみである。$X_1, \dotsc, X_n$が独立同分布であれば、この条件は当然成り立つ。
\end{example}

\begin{example}[期待値が既知の場合の分散の不偏推定量]
    標本$X_1, \dotsc, X_n$のそれぞれが、期待値$\mu$, 分散$\sigma^2$の分布にしたがうとする。今、$\mu$は既知であり、$\sigma^2$を推定したいとする。
    \begin{equation}
        S^2(\mu) := \frac{1}{n}\sum_{i=1}^n(X_i-\mu)^2
    \end{equation}
    とすると、$S^2(\mu)$は分散$\sigma^2$の不偏推定量である。
    \begin{equation}
        E[S^2(\mu)]
        = E\left[\frac{1}{n}\sum_{i=1}^n(X_i-\mu)^2\right]
        = \frac{1}{n}\sum_{i=1}^nE[(X_i-\mu)^2]
        = \sigma^2
    \end{equation}
    この導出で使用しているのは、各$X_i$の期待値、分散が$\mu$, $\sigma^2$であるという前提のみである。$X_1, \dotsc, X_n$が独立同分布であれば、この条件は当然成り立つ。
\end{example}

\begin{example}[期待値が未知の場合の分散の不偏推定量]\label{u_est_var}
    標本$X_1, \dotsc, X_n$のそれぞれが、期待値$\mu$, 分散$\sigma^2$の分布にしたがうとする。今、$\mu$, $\sigma^2$はともに未知であるとする。例\ref{u_est_exp}より、$\bar{X}$は$\mu$の不偏推定量である。\term{標本分散 (sample variance)} $S^2$を以下で定義する。
    \begin{equation}
        S^2 := \frac{1}{n}\sum_{i=1}^n (X_i - \bar{X})^2
    \end{equation}
    $S^2$は以下のように式変形できる。
    \begin{equation}
        \begin{split}
            S^2
            &= \frac{1}{n}\sum_{i=1}^n ((X_i - \mu) - (\bar{X} - \mu))^2\\
            &= \frac{1}{n}\sum_{i=1}^n (X_i - \mu)^2
            - \frac{2}{n}(\bar{X} - \mu)\sum_{i=1}^n (X_i - \mu)
            +(\bar{X} - \mu)^2\\
            &= \frac{1}{n}\sum_{i=1}^n (X_i - \mu)^2
            -(\bar{X} - \mu)^2
        \end{split}
    \end{equation}
    ここで、標本平均$\bar{X}$の分散を計算しておく。
    \begin{equation}
        V[\bar{X}] = E[(\bar{X} - \mu)^2]
        = E\left[\left(\sum_{i=1}^n\frac{X_i - \mu}{n}\right)^2\right]
        = E\left[\sum_{i=1}^n\sum_{j=1}^n\frac{X_i - \mu}{n}\frac{X_j - \mu}{n}\right]
    \end{equation}
    $X_i, X_j (i \neq j)$が独立ならば$E[(X_i-\mu)(X_j-\mu)] = E[(X_i-\mu)]E[(X_j-\mu)] = 0$であるから、$X_i$の期待値$\mu$, 分散$\sigma^2$を使って
    \begin{equation}
        V[\bar{X}] = E[(\bar{X} - \mu)^2]
        = E\left[\sum_{i=1}^n\left(\frac{X_i - \mu}{n}\right)^2\right]
        = \frac{\sigma^2}{n}
    \end{equation}
    したがって、標本分散$S^2$の期待値は
    \begin{equation}
        E[S^2]
        = \frac{1}{n}\sum_{i=1}^n V[X_i] - \frac{\sigma^2}{n}
        = \frac{n-1}{n}\sigma^2
    \end{equation}
    となり、$S^2$は分散$\sigma^2$の不偏推定量ではない。あらためて
    \begin{equation}
        S_0^2 := \frac{n}{n-1}S^2
        = \frac{1}{n-1}\sum_{i=1}^n (X_i - \bar{X})^2
    \end{equation}
    と定義すると、$S_0^2$は分散$\sigma^2$の不偏推定量になる。$S_0^2$を\term{不偏分散 (unbiased variance)}と呼ぶ。以上の計算では$X_1, \dotsc, X_n$が独立同分布であることを用いた。
\end{example}

\begin{note}
    「標本分散」という言葉の使われ方は曖昧で、$n$で割るものを指す場合、$n-1$で割るものを指す場合、両方を指す場合があるらしい。また記号も、$s^2$や$\hat{\sigma}^2$をどちらか（どちらも）に使うことがある。この文書では上の例で書いている通り、$n$で割るものを標本分散$S^2$, $n-1$で割るものを不偏分散$S_0^2$とする。
\end{note}

\begin{example}[期待値が未知の場合の共分散の不偏推定量]
    標本$(X_1, Y_1), \dotsc, (X_n, Y_n)$のそれぞれが、期待値$\mu_X$, $\mu_Y$, 共分散$\sigma_{XY}$の分布にしたがうとする。今、$\mu_X$, $\mu_Y$, $\sigma_{XY}$は未知であるとする。例\ref{u_est_exp}より、$\bar{X}$, $\bar{Y}$は$\mu_X$, $\mu_Y$の不偏推定量である。\term{標本共分散 (sample covariance)} $S_{XY}$を以下で定義する。
    \begin{equation}
        S_{XY} := \frac{1}{n} \sum_{i=1}^n (X_i - \bar{X})(Y_i - \bar{Y})
    \end{equation}
    $S_{XY}$は以下のように式変形できる。
    \begin{equation}
        \begin{split}
            S_{XY}
            &= \frac{1}{n}\sum_{i=1}^n
            \left((X_i-\mu_X)-(\bar{X}-\mu_X)\right)
            \left((Y_i-\mu_Y)-(\bar{Y}-\mu_Y)\right) \\
            &= \frac{1}{n}\sum_{i=1}^n (X_i - \mu_X)(Y_i - \mu_Y)
            + (\bar{X} - \mu_X)(\bar{Y} - \mu_Y) \\
            &\quad - \frac{1}{n}(\bar{X} - \mu_X) \sum_{i=1}^n (Y_i - \mu_Y)
            - \frac{1}{n}(\bar{Y} - \mu_X) \sum_{i=1}^n (X_i - \mu_X) \\
            &= \frac{1}{n}\sum_{i=1}^n (X_i - \mu_X)(Y_i - \mu_Y)
            - (\bar{X} - \mu_X)(\bar{Y} - \mu_Y)
        \end{split}
    \end{equation}
    ここで、標本平均$\bar{X}$, $\bar{Y}$の共分散を計算しておく。
    \begin{equation}
        \operatorname{Cov}[\bar{X}, \bar{Y}]
        = E[(\bar{X} - \mu_X)(\bar{Y} - \mu_Y)]
        = E\left[\sum_{i, j=1}^n\frac{X_i - \mu_X}{n}\frac{Y_j - \mu_Y}{n}\right]
    \end{equation}
    $(X_i, Y_i)$, $(X_j, Y_j)$ ($i \neq j$)が独立ならば$E[(X_i-\mu_X)(Y_i-\mu_Y)] = E[(X_i-\mu_X)]E[(Y_i-\mu_Y)] = 0$であるから、
    \begin{equation}
        \operatorname{Cov}[\bar{X}, \bar{Y}]
        = E[(\bar{X} - \mu_X)(\bar{Y} - \mu_Y)]
        = E\left[\sum_{i=1}^n\frac{X_i - \mu_X}{n}\frac{Y_i - \mu_Y}{n}\right]
        = \frac{\sigma_{XY}}{n}
    \end{equation}
    したがって、標本共分散$S_{XY}$の期待値は
    \begin{equation}
        E[S_{XY}]
        = \frac{1}{n}\sum_{i=1}^n E[(X_i - \mu_X)(Y_i - \mu_Y)] - \frac{\sigma_{XY}}{n}
        = \frac{n-1}{n}\sigma_{XY}
    \end{equation}
    となり、$S_{XY}$は共分散$\sigma_{XY}$の不偏推定量ではない。あらためて
    \begin{equation}
        S_{XY0} := \frac{n}{n-1}S_{XY}
        = \frac{1}{n-1} \sum_{i=1}^n (X_i - \bar{X})(Y_i - \bar{Y})
    \end{equation}
    と定義すると、$X_{XY0}$は共分散$\sigma_{XY}$の不偏推定量になる。$S_{XY0}$を\term{不偏共分散 (unbiased covariance)}と呼ぶ。以上の計算では$(X_1, Y_1), \dotsc, (X_n, Y_n)$が独立同分布であることを用いた。
\end{example}

パラメーター$\theta$の不偏推定量$\hat{\theta}(\boldsymbol{X})$が与えられた時に、$\theta$の関数$g(\theta)$に対して、$g(\hat{\theta}(\boldsymbol{X}))$は一般に不偏推定量ではない。

\begin{example}[期待値の関数の推定]
    期待値$\mu$の関数$g(\mu)$を考える。標本平均$\bar{X}=\sum_i X_i/n$は$\mu$の不偏推定量だった。$g(\bar{X})$が$g(\mu)$の不偏推定量になるかを考える。$g$が線形な関数であれば、
    \begin{equation}
        E[g(\bar{X})]
        = E\left[g\left(\frac{1}{n}\sum_{i=1}^n X_i\right)\right]
        = \frac{1}{n}\sum_{i=1}^n E[g(X_i)]
    \end{equation}
    さらに
    \begin{equation}
        E[g(X)] = \sum_x g(x)p_X(x)
        = g\left(\sum_x x\cdot p_X(x)\right)
        = g(E[X]) = g(\mu)
    \end{equation}
    より
    \begin{equation}
        E[g(\bar{X})] = g(\mu)
    \end{equation}
    となり、$g(\bar{X})$は$g(\mu)$の不偏推定量になることが分かる。$g$が線形でない場合は必ずしも不偏推定量になるとはいえない。そのずれの大きさを見てみよう。確率変数$\bar{X}$の期待値からのずれ$\delta := \bar{X} - \mu$を定義し、$g(\bar{X})$を$g(\mu)$の周りで$\delta$で展開してみる\footnote{この計算は確率変数$\delta$を単なる微小な数とみなして行っており、正確な議論ではない。}。
    \begin{equation}
        g(\bar{X})
        = g(\mu) + g'(\mu)\delta + \frac{1}{2}g''(\mu)\delta^2 + O(\delta^3)
    \end{equation}
    ここで、$\delta$は期待値0, 分散$\sigma^2/n$（例\ref{u_est_var}での$V[\bar{X}]$の計算を参照）の確率変数なので、$g(\bar{X})$の偏りは
    \begin{equation}
        E[g(\bar{X})] - g(\mu) = O\left(\frac{1}{n}\right)
    \end{equation}
    となり、$1/n$のオーダーの偏りが残ることが分かる。
\end{example}

上の偏りの評価を一般化しておく\footnote{上記と同様、数学的に正確な議論ではない。}。$g(\hat{\theta}(\boldsymbol{X}))$の偏りは
\begin{equation}
    E[g(\hat{\theta}(\boldsymbol{X}))] - g(\theta)
    = \frac{1}{2}g''(\theta)V[\hat{\theta}(\boldsymbol{X})] + O(\delta^3)
\end{equation}
であり、$g$が非線形な場合は不偏でない。

\begin{example}[分散の関数・標準偏差の推定]\label{est_sd}
    分散$\sigma^2$の関数$g(\sigma^2)$を考える。不偏分散$S_0^2$は$\sigma^2$の不偏推定量だった。\cite{u_var_var}によると、$X_i$の4次の中心モーメント$\mu_4$の存在を仮定すると、
    \begin{equation}
        V[S_0^2]
        = \frac{1}{n}\left(\mu_4 - \frac{n-3}{n-1}\sigma^4\right)
    \end{equation}
    したがって$g(S_0^2)$の$g(\sigma^2)$の推定量としての偏りはやはり$O(1/n)$。特に標準偏差$\sigma := \sqrt{\sigma^2}$を考えると、$(\sqrt{x})'' = -x^{-3/2}/4$より、偏りのリーディングオーダーは
    \begin{equation}
        \frac{1}{2}\left(-\frac{\sigma^{-3}}{4}\right)V[S_0^2]
        = -\frac{\sigma^{-3}}{8}
        \left(\mu_4 - \frac{n-3}{n-1}\sigma^4\right)
        \frac{1}{n}
    \end{equation}
\end{example}

このように、$\sqrt{S_0^2}$は標準偏差の不偏推定量ではないが、一方で分布を問わない標準偏差の不偏推定量は知られていない（正規分布など、特定の分布で不偏推定量が知られているものはある）ため、$\sqrt{S_0^2}$を標準偏差の推定量として使うことが多い。

なお、不偏推定量の誤差（後述）が、不偏でない推定量より大きくなる場合もあり、不偏性にこだわりすぎるべきではないという注意もある\cite{kuroki}。

\subsection{推定量の誤差}

推定量は確率変数なので、パラメーターの推定値は確率的な値として得られることになる。推定値が平均的にはパラメーターと一致するというのが不偏性であったが、得られる推定値が実際にどの程度ずれるかを見るためには、推定量の確率的なばらつきを考慮に入れる必要がある。

パラメーター$\theta$と推定値$\hat{\theta}(\boldsymbol{X})$のずれを評価するために、\term{損失関数 (loss function)} $L(\theta, \hat{\theta}(\boldsymbol{X}))$を考えよう。ここで損失関数$L$は任意の$x$, $y$に対して$L(x, y) \geq 0$, $L(x, x) = 0$を満たすものとする。損失関数の期待値
\begin{equation}
    R(\theta, \hat{\theta}) := E[L(\theta, \hat{\theta}(\boldsymbol{X}))]
\end{equation}
を\term{リスク関数 (risk function)}という。リスク関数は、損失関数$L$の選び方に応じたある種の推定量の「誤差」を評価していると解釈できる。特に$L$を2乗損失$L(x, y):=(x-y)^2$とするとき、$\hat{\theta}$のリスク関数を$\hat{\theta}$の\term{平均2乗誤差 (mean squared error, MSE)}と呼び、
\begin{equation}
    \operatorname{MSE}(\hat{\theta}) := E[(\hat{\theta}(\boldsymbol{X}) - \theta)^2]
\end{equation}
と書く。
\begin{equation}
    \begin{split}
    \operatorname{MSE}(\hat{\theta})
    &= E\left[\left(
        (\hat{\theta}(\boldsymbol{X}) - E[\hat{\theta}(\boldsymbol{X})]) +
        (E[\hat{\theta}(\boldsymbol{X})] - \theta)
    \right)^2\right] \\
    &= E[(\hat{\theta}(\boldsymbol{X}) - E[\hat{\theta}(\boldsymbol{X})])^2] +
    (E[\hat{\theta}(\boldsymbol{X})] - \theta)^2 \\
    &= V[\hat{\theta}(\boldsymbol{X})] +
    (E[\hat{\theta}(\boldsymbol{X})] - \theta)^2
    \end{split}
\end{equation}
より、MSEは推定量$\hat{\theta}(\boldsymbol{X})$の分散と、推定量の期待値の$\theta$からのずれの2乗の和になる。特に$\hat{\theta}(\boldsymbol{X})$が$\theta$の不偏推定量の場合、$\operatorname{MSE}(\hat{\theta}) = V[\hat{\theta}]$であり、推定量の分散（または標準偏差）で推定の誤差を評価できる。推定量の標準偏差を\term{標準誤差 (standard error)}と呼び、推定誤差の尺度としてよく用いられる。

\begin{example}[標本平均の誤差（標準誤差）]
    $X_1, \dotsc, X_n$が期待値$\mu$, 分散$\sigma^2$の独立同分布であるとき、標本平均$\bar{X}$は期待値$\mu$の不偏推定量であった。$\bar{X}$の分散を例\ref{u_est_var}で計算したが、ここにも再度載せておく。
    \begin{equation}
        V[\bar{X}] = E[(\bar{X} - \mu)^2]
        = E\left[\left(\sum_{i=1}^n\frac{X_i - \mu}{n}\right)^2\right]
        = E\left[\sum_{i=1}^n\sum_{j=1}^n\frac{X_i - \mu}{n}\frac{X_j - \mu}{n}\right]
    \end{equation}
    $X_i, X_j (i \neq j)$が独立なので$E[(X_i-\mu)(X_j-\mu)] = E[(X_i-\mu)]E[(X_j-\mu)]$であるから、$X_i$の期待値$\mu$, 分散$\sigma^2$を使って
    \begin{equation}
        V[\bar{X}] = E[(\bar{X} - \mu)^2]
        = E\left[\sum_{i=1}^n\left(\frac{X_i - \mu}{n}\right)^2\right]
        = \frac{\sigma^2}{n}
    \end{equation}
    $\mu$の不偏推定量$\bar{X}$の標準誤差は、$\sqrt{V[\bar{X}]}=\sigma/\sqrt{n}$である。$\sigma$が未知の場合、この標準誤差自体も未知であり推定の対象となる。例\ref{est_sd}とその直後で述べたように、$\sigma$の（不偏ではない）推定量として不偏分散$S_0^2$の2乗根を使うと、標準誤差を$\sqrt{S_0^2/n}$で推定できる。なお例\ref{est_sd}で見た通り、$\sigma$の推定量としての$\sqrt{S_0^2}$の偏りは$O(1/n)$であるから、標準誤差の推定における偏りは$O(n^{-3/2})$である。
\end{example}

よい推定を行うためにはできるだけ誤差の小さい推定量を見つけたいが、一般には、対象とする（パラメトリックな）分布族の関数形を特定しなければそのような議論はできない。一方、分布の形を限定せずに成り立つ重要な性質として\term{クラメール・ラオの不等式 (Cram\'{e}r-Rao inequality)}がある。

標本$\boldsymbol{X} = (X_1, \dotsc, X_n)$の分布関数が、パラメーター$\theta$を含む関数$f_{\boldsymbol{X}}(\boldsymbol{X}; \theta)$であるとする。この時、\term{フィッシャー情報量 (Fisher information)}を以下で定義する（適当な微分可能性を仮定する）。
\begin{equation}
    I_{\boldsymbol{X}}(\theta) := E_\theta\left[
        \left(
            \frac{\partial}{\partial \theta}
            \log f_{\boldsymbol{X}}(\boldsymbol{X}; \theta)
        \right)^2
    \right]
\end{equation}

以下、$f_{\boldsymbol{X}}(\boldsymbol{X}; \theta)$が適当な正則条件（$\boldsymbol{X}$に関する和・積分と$\theta$に関する微分が交換可能など）を満たすことを仮定する。この時、以下が成り立つ。

\begin{theorem}[クラメール・ラオ(Cram\'{e}r-Rao)の不等式]
    微分可能な関数$g(\theta)$の任意の不偏推定量$\hat{g}=\hat{g}(\boldsymbol{X})$について、
    \begin{equation}
        V_\theta[\hat{g}] \geq
        \frac{(g'(\theta))^2}{I_{\boldsymbol{X}}(\theta)}
    \end{equation}
    が成り立つ。右辺を\term{クラメール・ラオの下界 (Cram\'{e}r-Rao bound)}という。等号は以下の場合にのみ成り立つ。
    \begin{equation}
        \frac{\partial}{\partial\theta}
        \log f_{\boldsymbol{X}}(\boldsymbol{X}; \theta)
        = I_{\boldsymbol{X}}(\theta)
        \frac{\hat{g}(\boldsymbol{x}) - g(\theta)}{g'(\theta)}
    \end{equation}
\end{theorem}

ここで、$g(\theta)=\theta$, $\hat{g}=\hat{\theta}$の場合を考えると、
\begin{equation}
    V_\theta[\hat{\theta}] \geq \frac{1}{I_{\boldsymbol{X}}(\theta)}
\end{equation}

また、$\hat{g}(\boldsymbol{X})$が偏り$b(\theta):=E_\theta[\hat{g}(\boldsymbol{X})]-g(\theta)$を持つ場合を考えると、$\hat{g}(\boldsymbol{X})$は$g(\theta)+b(\theta)$の不偏推定量と考えられるから、これにCR不等式を適用すると
\begin{equation}
    V_\theta[\hat{g}] \geq
    \frac{(g'(\theta)+b'(\theta))^2}{I_{\boldsymbol{X}}(\theta)}
\end{equation}
MSEは推定量の分散と偏りの2乗の和だったから、MSEには以下の下界が存在することが分かる。
\begin{equation}
    \operatorname{MSE}_\theta(\hat{g}) \geq
    \frac{(g'(\theta)+b'(\theta))^2}{I_{\boldsymbol{X}}(\theta)}
    + b(\theta)^2
\end{equation}
$|g'(\theta)+b'(\theta)|< |g'(\theta)|$となる場合、$V_\theta[\hat{g}]$, $\operatorname{MSE}_\theta(\hat{g})$はCRの下界を下回る場合もある。

なお、CRの下界を達成する不偏推定量は存在しない場合もある。

$X_1, \dotsc, X_n$が、分布$p(x; \theta)$からの無作為標本（独立同分布）の場合、$I_{\boldsymbol{X}}(\theta) - nI_{X_1}(\theta)$となり、
\begin{equation}
    V_\theta[\hat{g}] \geq
    \frac{(g'(\theta))^2}{nI_{X_1}(\theta)}
\end{equation}
したがって、推定量の分散は最良で$1/n$のスケーリングになることが分かる。したがって標本平均は、$n$に関するスケーリングとしては最良である。

\section{大標本の漸近的な性質}

期待値$\mu$, 分散$\sigma^2>0$の分布からの無作為標本（独立同分布）$X_1, \dotsc, X_n$について、$n\to\infty$で漸近的に成り立つ性質について紹介する。$n$がある程度大きい時の近似として有効かもしれない。

\subsection{大数の法則}

標本平均$\bar{X} := \sum_{i=1}^n X_i/n$について、その期待値と分散はそれぞれ$\mu$, $\sigma^2/n$なので、標本平均の分布に関するチェビシェフの不等式において$a=\varepsilon\sqrt{n}/\sigma$（$\varepsilon$は任意の正数）とすると、
\begin{equation}
    P\{|\bar{X} - \mu| > \varepsilon\} \leq \frac{\sigma^2}{\varepsilon^2 n}
\end{equation}
が成り立つ。したがって$n\to\infty$とすれば、以下の\term{大数の（弱）法則 ((weak) law of large numbers)}が成り立つ。

\begin{theorem}[大数の（弱）法則]
    任意の正数$\varepsilon$について、標本平均$\bar{X}$と期待値$\mu$が$\varepsilon$より大きくずれる確率は、$n\to\infty$で$0$に収束する。
    \begin{equation}
        \lim_{n\to\infty} P\{|\bar{X} - \mu|>\varepsilon\} = 0
    \end{equation}
\end{theorem}

\subsection{中心極限定理}

標本平均$\bar{X} := \sum_{i=1}^n X_i/n$の分布は、$n\to\infty$で期待値$\mu$, 分散$\sigma^2/n$の正規分布に収束する。これを\term{中心極限定理 (central limit theorem, CLT)}という。

\begin{theorem}[中心極限定理]
    $\sqrt{n}(\bar{X}-\mu)/\sigma$の分布は、$n\to\infty$で標準正規分布$N(0, 1)$に収束する。すなわち$N(0, 1)$の累積分布関数を$\Phi(t)$とすると、任意の実数$t$について
    \begin{equation}
        \lim_{n\to\infty} P\left\{
            \frac{\sqrt{n}(\bar{X}-\mu)}{\sigma} \leq t
        \right\} = \Phi(t)
    \end{equation}
    が成り立つ。
\end{theorem}

\begin{note}
    前節で見た通り、$n$が有限でも$\bar{X}$の期待値と分散はそれぞれ$\mu$, $\sigma^2/n$であることが示せる。したがって中心極限定理は、$n\to\infty$での3次以上のモーメントの振る舞いを決めているだけ、と考えることができる？
\end{note}

\begin{thebibliography}{9}
    \bibitem{akahira}
        赤平昌文『統計的不偏推定論』
        統計学One Point 17（共立出版、2019）
        \url{https://www.kyoritsu-pub.co.jp/book/b10003219.html}
    \bibitem{u_var_var}
        不偏分散の分散
        \url{https://qiita.com/nloglogn/items/b863f8cea0ec6da42af3}
    \bibitem{kuroki}
        \url{https://twitter.com/genkuroki/status/1554714353081155585?s=20},\\
        \url{https://twitter.com/genkuroki/status/1554714834633379840?s=20}
\end{thebibliography}

\end{document}
